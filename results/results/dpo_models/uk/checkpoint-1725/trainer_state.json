{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 3.0,
  "eval_steps": 500,
  "global_step": 1725,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.034782608695652174,
      "grad_norm": 10.491105079650879,
      "learning_rate": 5.491329479768787e-06,
      "logits/chosen": -1.631163239479065,
      "logits/rejected": -1.4476722478866577,
      "logps/chosen": -217.27182006835938,
      "logps/rejected": -211.0649871826172,
      "loss": 0.6974,
      "rewards/accuracies": 0.4625000059604645,
      "rewards/chosen": -0.005158791318535805,
      "rewards/margins": -0.007735928986221552,
      "rewards/rejected": 0.0025771362707018852,
      "step": 20
    },
    {
      "epoch": 0.06956521739130435,
      "grad_norm": 9.2897367477417,
      "learning_rate": 1.1271676300578036e-05,
      "logits/chosen": -1.822583794593811,
      "logits/rejected": -1.5992201566696167,
      "logps/chosen": -241.3654327392578,
      "logps/rejected": -243.3793487548828,
      "loss": 0.6905,
      "rewards/accuracies": 0.550000011920929,
      "rewards/chosen": 0.006246805191040039,
      "rewards/margins": 0.006294022314250469,
      "rewards/rejected": -4.7215820814017206e-05,
      "step": 40
    },
    {
      "epoch": 0.10434782608695652,
      "grad_norm": 7.447085857391357,
      "learning_rate": 1.7052023121387284e-05,
      "logits/chosen": -1.4912629127502441,
      "logits/rejected": -1.3937240839004517,
      "logps/chosen": -238.1490478515625,
      "logps/rejected": -200.37399291992188,
      "loss": 0.6928,
      "rewards/accuracies": 0.42500001192092896,
      "rewards/chosen": -0.001367161050438881,
      "rewards/margins": 0.0015466026961803436,
      "rewards/rejected": -0.0029137632809579372,
      "step": 60
    },
    {
      "epoch": 0.1391304347826087,
      "grad_norm": 12.7888765335083,
      "learning_rate": 2.2832369942196533e-05,
      "logits/chosen": -1.5580358505249023,
      "logits/rejected": -1.5074996948242188,
      "logps/chosen": -236.3167724609375,
      "logps/rejected": -229.3868408203125,
      "loss": 0.6822,
      "rewards/accuracies": 0.637499988079071,
      "rewards/chosen": 0.011288623325526714,
      "rewards/margins": 0.02307860367000103,
      "rewards/rejected": -0.01178998127579689,
      "step": 80
    },
    {
      "epoch": 0.17391304347826086,
      "grad_norm": 6.6513991355896,
      "learning_rate": 2.861271676300578e-05,
      "logits/chosen": -1.3026552200317383,
      "logits/rejected": -1.2026879787445068,
      "logps/chosen": -224.55496215820312,
      "logps/rejected": -214.1123809814453,
      "loss": 0.6991,
      "rewards/accuracies": 0.4000000059604645,
      "rewards/chosen": -0.008400386199355125,
      "rewards/margins": -0.010792994871735573,
      "rewards/rejected": 0.002392607042565942,
      "step": 100
    },
    {
      "epoch": 0.20869565217391303,
      "grad_norm": 11.863154411315918,
      "learning_rate": 3.439306358381503e-05,
      "logits/chosen": -1.7810747623443604,
      "logits/rejected": -1.5585225820541382,
      "logps/chosen": -242.91140747070312,
      "logps/rejected": -220.4741973876953,
      "loss": 0.6943,
      "rewards/accuracies": 0.550000011920929,
      "rewards/chosen": 0.021230950951576233,
      "rewards/margins": -0.0004301317094359547,
      "rewards/rejected": 0.02166108414530754,
      "step": 120
    },
    {
      "epoch": 0.24347826086956523,
      "grad_norm": 11.909296035766602,
      "learning_rate": 4.0173410404624276e-05,
      "logits/chosen": -1.6506967544555664,
      "logits/rejected": -1.5923144817352295,
      "logps/chosen": -250.0253448486328,
      "logps/rejected": -222.3214111328125,
      "loss": 0.6874,
      "rewards/accuracies": 0.6000000238418579,
      "rewards/chosen": 0.022801285609602928,
      "rewards/margins": 0.013703410513699055,
      "rewards/rejected": 0.009097878821194172,
      "step": 140
    },
    {
      "epoch": 0.2782608695652174,
      "grad_norm": 8.816642761230469,
      "learning_rate": 4.595375722543353e-05,
      "logits/chosen": -1.5072596073150635,
      "logits/rejected": -1.3504022359848022,
      "logps/chosen": -233.9293212890625,
      "logps/rejected": -246.2406005859375,
      "loss": 0.6799,
      "rewards/accuracies": 0.5874999761581421,
      "rewards/chosen": 0.06418308615684509,
      "rewards/margins": 0.03313217684626579,
      "rewards/rejected": 0.0310509093105793,
      "step": 160
    },
    {
      "epoch": 0.3130434782608696,
      "grad_norm": 9.22773265838623,
      "learning_rate": 4.999815615891943e-05,
      "logits/chosen": -1.6927759647369385,
      "logits/rejected": -1.5973807573318481,
      "logps/chosen": -230.47525024414062,
      "logps/rejected": -227.76303100585938,
      "loss": 0.6821,
      "rewards/accuracies": 0.612500011920929,
      "rewards/chosen": 0.13868704438209534,
      "rewards/margins": 0.036040473729372025,
      "rewards/rejected": 0.10264655202627182,
      "step": 180
    },
    {
      "epoch": 0.34782608695652173,
      "grad_norm": 9.910919189453125,
      "learning_rate": 4.996538432757414e-05,
      "logits/chosen": -1.8051449060440063,
      "logits/rejected": -1.6155608892440796,
      "logps/chosen": -222.9287872314453,
      "logps/rejected": -236.88644409179688,
      "loss": 0.6999,
      "rewards/accuracies": 0.44999998807907104,
      "rewards/chosen": 0.08839137852191925,
      "rewards/margins": 0.0010770895751193166,
      "rewards/rejected": 0.08731429278850555,
      "step": 200
    },
    {
      "epoch": 0.3826086956521739,
      "grad_norm": 11.190359115600586,
      "learning_rate": 4.989170006943763e-05,
      "logits/chosen": -1.6819671392440796,
      "logits/rejected": -1.5348830223083496,
      "logps/chosen": -235.8510284423828,
      "logps/rejected": -208.32803344726562,
      "loss": 0.6665,
      "rewards/accuracies": 0.6000000238418579,
      "rewards/chosen": 0.15915291011333466,
      "rewards/margins": 0.07019259035587311,
      "rewards/rejected": 0.08896033465862274,
      "step": 220
    },
    {
      "epoch": 0.41739130434782606,
      "grad_norm": 10.985336303710938,
      "learning_rate": 4.977722413577802e-05,
      "logits/chosen": -1.7689911127090454,
      "logits/rejected": -1.6652103662490845,
      "logps/chosen": -249.295166015625,
      "logps/rejected": -218.7556915283203,
      "loss": 0.6782,
      "rewards/accuracies": 0.574999988079071,
      "rewards/chosen": 0.1583012193441391,
      "rewards/margins": 0.04955507442355156,
      "rewards/rejected": 0.10874614864587784,
      "step": 240
    },
    {
      "epoch": 0.45217391304347826,
      "grad_norm": 10.592679023742676,
      "learning_rate": 4.9622144125880535e-05,
      "logits/chosen": -1.6227905750274658,
      "logits/rejected": -1.5600934028625488,
      "logps/chosen": -224.20382690429688,
      "logps/rejected": -224.2791290283203,
      "loss": 0.6518,
      "rewards/accuracies": 0.550000011920929,
      "rewards/chosen": 0.20289066433906555,
      "rewards/margins": 0.12205536663532257,
      "rewards/rejected": 0.08083529770374298,
      "step": 260
    },
    {
      "epoch": 0.48695652173913045,
      "grad_norm": 11.959235191345215,
      "learning_rate": 4.942671417961614e-05,
      "logits/chosen": -1.6044862270355225,
      "logits/rejected": -1.6369969844818115,
      "logps/chosen": -238.0632781982422,
      "logps/rejected": -220.85049438476562,
      "loss": 0.6852,
      "rewards/accuracies": 0.5249999761581421,
      "rewards/chosen": 0.1279434859752655,
      "rewards/margins": 0.04200577735900879,
      "rewards/rejected": 0.08593772351741791,
      "step": 280
    },
    {
      "epoch": 0.5217391304347826,
      "grad_norm": 10.445197105407715,
      "learning_rate": 4.9191254560965735e-05,
      "logits/chosen": -1.7837282419204712,
      "logits/rejected": -1.6772807836532593,
      "logps/chosen": -205.60952758789062,
      "logps/rejected": -189.4821014404297,
      "loss": 0.6792,
      "rewards/accuracies": 0.48750001192092896,
      "rewards/chosen": 0.19722668826580048,
      "rewards/margins": 0.06059493497014046,
      "rewards/rejected": 0.13663174211978912,
      "step": 300
    },
    {
      "epoch": 0.5565217391304348,
      "grad_norm": 17.6357364654541,
      "learning_rate": 4.891615113318236e-05,
      "logits/chosen": -1.5657587051391602,
      "logits/rejected": -1.4887416362762451,
      "logps/chosen": -264.5914611816406,
      "logps/rejected": -262.7719421386719,
      "loss": 0.7073,
      "rewards/accuracies": 0.5625,
      "rewards/chosen": 0.14965710043907166,
      "rewards/margins": 0.007308089639991522,
      "rewards/rejected": 0.1423490345478058,
      "step": 320
    },
    {
      "epoch": 0.591304347826087,
      "grad_norm": 9.487445831298828,
      "learning_rate": 4.860185472645161e-05,
      "logits/chosen": -1.5595483779907227,
      "logits/rejected": -1.5519402027130127,
      "logps/chosen": -244.7066650390625,
      "logps/rejected": -212.8419952392578,
      "loss": 0.6728,
      "rewards/accuracies": 0.574999988079071,
      "rewards/chosen": 0.18780364096164703,
      "rewards/margins": 0.06568476557731628,
      "rewards/rejected": 0.12211885303258896,
      "step": 340
    },
    {
      "epoch": 0.6260869565217392,
      "grad_norm": 23.626962661743164,
      "learning_rate": 4.824888039908629e-05,
      "logits/chosen": -1.6603587865829468,
      "logits/rejected": -1.541102409362793,
      "logps/chosen": -254.0594482421875,
      "logps/rejected": -258.052490234375,
      "loss": 0.6776,
      "rewards/accuracies": 0.612500011920929,
      "rewards/chosen": 0.1251203715801239,
      "rewards/margins": 0.060065943747758865,
      "rewards/rejected": 0.06505443900823593,
      "step": 360
    },
    {
      "epoch": 0.6608695652173913,
      "grad_norm": 11.73104476928711,
      "learning_rate": 4.7857806593466415e-05,
      "logits/chosen": -1.5389630794525146,
      "logits/rejected": -1.524295687675476,
      "logps/chosen": -239.89437866210938,
      "logps/rejected": -203.10340881347656,
      "loss": 0.6952,
      "rewards/accuracies": 0.574999988079071,
      "rewards/chosen": 0.09927309304475784,
      "rewards/margins": 0.016357125714421272,
      "rewards/rejected": 0.08291596174240112,
      "step": 380
    },
    {
      "epoch": 0.6956521739130435,
      "grad_norm": 9.117112159729004,
      "learning_rate": 4.742927418810727e-05,
      "logits/chosen": -1.6772689819335938,
      "logits/rejected": -1.4807159900665283,
      "logps/chosen": -211.6808319091797,
      "logps/rejected": -217.20706176757812,
      "loss": 0.6683,
      "rewards/accuracies": 0.5625,
      "rewards/chosen": 0.05368991568684578,
      "rewards/margins": 0.07089392840862274,
      "rewards/rejected": -0.017204012721776962,
      "step": 400
    },
    {
      "epoch": 0.7304347826086957,
      "grad_norm": 7.379390239715576,
      "learning_rate": 4.696398544740955e-05,
      "logits/chosen": -1.7369073629379272,
      "logits/rejected": -1.6077184677124023,
      "logps/chosen": -211.93295288085938,
      "logps/rejected": -218.9477081298828,
      "loss": 0.6612,
      "rewards/accuracies": 0.625,
      "rewards/chosen": 0.08718466758728027,
      "rewards/margins": 0.10328324884176254,
      "rewards/rejected": -0.016098588705062866,
      "step": 420
    },
    {
      "epoch": 0.7652173913043478,
      "grad_norm": 9.225706100463867,
      "learning_rate": 4.646270287081208e-05,
      "logits/chosen": -1.565383791923523,
      "logits/rejected": -1.4292114973068237,
      "logps/chosen": -222.14230346679688,
      "logps/rejected": -211.9297637939453,
      "loss": 0.6676,
      "rewards/accuracies": 0.612500011920929,
      "rewards/chosen": 0.11689448356628418,
      "rewards/margins": 0.08429446071386337,
      "rewards/rejected": 0.032600030303001404,
      "step": 440
    },
    {
      "epoch": 0.8,
      "grad_norm": 11.37580394744873,
      "learning_rate": 4.592624794323366e-05,
      "logits/chosen": -1.5936739444732666,
      "logits/rejected": -1.411012053489685,
      "logps/chosen": -271.232421875,
      "logps/rejected": -251.8546142578125,
      "loss": 0.6849,
      "rewards/accuracies": 0.574999988079071,
      "rewards/chosen": 0.07500316202640533,
      "rewards/margins": 0.05375262349843979,
      "rewards/rejected": 0.021250545978546143,
      "step": 460
    },
    {
      "epoch": 0.8347826086956521,
      "grad_norm": 11.248802185058594,
      "learning_rate": 4.535549978885132e-05,
      "logits/chosen": -1.8899414539337158,
      "logits/rejected": -1.5500552654266357,
      "logps/chosen": -243.83633422851562,
      "logps/rejected": -231.71865844726562,
      "loss": 0.6808,
      "rewards/accuracies": 0.5249999761581421,
      "rewards/chosen": 0.12783758342266083,
      "rewards/margins": 0.07901575416326523,
      "rewards/rejected": 0.0488218292593956,
      "step": 480
    },
    {
      "epoch": 0.8695652173913043,
      "grad_norm": 11.596789360046387,
      "learning_rate": 4.47513937304214e-05,
      "logits/chosen": -1.7537282705307007,
      "logits/rejected": -1.6534297466278076,
      "logps/chosen": -222.6535186767578,
      "logps/rejected": -201.93161010742188,
      "loss": 0.6822,
      "rewards/accuracies": 0.612500011920929,
      "rewards/chosen": 0.12209993600845337,
      "rewards/margins": 0.05503516644239426,
      "rewards/rejected": 0.06706477701663971,
      "step": 500
    },
    {
      "epoch": 0.9043478260869565,
      "grad_norm": 12.17381763458252,
      "learning_rate": 4.4114919756504274e-05,
      "logits/chosen": -1.826984167098999,
      "logits/rejected": -1.71662175655365,
      "logps/chosen": -247.86190795898438,
      "logps/rejected": -228.79891967773438,
      "loss": 0.6929,
      "rewards/accuracies": 0.5249999761581421,
      "rewards/chosen": 0.14421972632408142,
      "rewards/margins": 0.040181733667850494,
      "rewards/rejected": 0.10403798520565033,
      "step": 520
    },
    {
      "epoch": 0.9391304347826087,
      "grad_norm": 12.51425552368164,
      "learning_rate": 4.344712089910462e-05,
      "logits/chosen": -1.8727045059204102,
      "logits/rejected": -1.8043272495269775,
      "logps/chosen": -228.80294799804688,
      "logps/rejected": -224.1526641845703,
      "loss": 0.6265,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": 0.14012102782726288,
      "rewards/margins": 0.17462149262428284,
      "rewards/rejected": -0.03450044244527817,
      "step": 540
    },
    {
      "epoch": 0.9739130434782609,
      "grad_norm": 14.390357971191406,
      "learning_rate": 4.274909152438582e-05,
      "logits/chosen": -1.9256401062011719,
      "logits/rejected": -1.5831570625305176,
      "logps/chosen": -234.11767578125,
      "logps/rejected": -222.69140625,
      "loss": 0.7108,
      "rewards/accuracies": 0.5375000238418579,
      "rewards/chosen": 0.16774077713489532,
      "rewards/margins": 0.04568466916680336,
      "rewards/rejected": 0.12205610424280167,
      "step": 560
    },
    {
      "epoch": 1.008695652173913,
      "grad_norm": 6.072031021118164,
      "learning_rate": 4.2021975539259836e-05,
      "logits/chosen": -1.727219820022583,
      "logits/rejected": -1.597013235092163,
      "logps/chosen": -214.2891387939453,
      "logps/rejected": -249.5312042236328,
      "loss": 0.6228,
      "rewards/accuracies": 0.612500011920929,
      "rewards/chosen": 0.24580661952495575,
      "rewards/margins": 0.32342079281806946,
      "rewards/rejected": -0.07761414349079132,
      "step": 580
    },
    {
      "epoch": 1.0434782608695652,
      "grad_norm": 6.012359619140625,
      "learning_rate": 4.1266964516791164e-05,
      "logits/chosen": -1.7024723291397095,
      "logits/rejected": -1.6186773777008057,
      "logps/chosen": -231.3356475830078,
      "logps/rejected": -211.2332763671875,
      "loss": 0.4481,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": 0.506317675113678,
      "rewards/margins": 0.6994510889053345,
      "rewards/rejected": -0.19313344359397888,
      "step": 600
    },
    {
      "epoch": 1.0782608695652174,
      "grad_norm": 6.211531162261963,
      "learning_rate": 4.048529574348734e-05,
      "logits/chosen": -1.7322012186050415,
      "logits/rejected": -1.8091789484024048,
      "logps/chosen": -221.12716674804688,
      "logps/rejected": -215.5929718017578,
      "loss": 0.4516,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.3831615447998047,
      "rewards/margins": 0.7224674820899963,
      "rewards/rejected": -0.3393058776855469,
      "step": 620
    },
    {
      "epoch": 1.1130434782608696,
      "grad_norm": 7.057225227355957,
      "learning_rate": 3.9678250191675586e-05,
      "logits/chosen": -1.6970847845077515,
      "logits/rejected": -1.5628225803375244,
      "logps/chosen": -222.1651611328125,
      "logps/rejected": -239.8451690673828,
      "loss": 0.4254,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": 0.5154420733451843,
      "rewards/margins": 0.865509033203125,
      "rewards/rejected": -0.35006698966026306,
      "step": 640
    },
    {
      "epoch": 1.1478260869565218,
      "grad_norm": 8.18460750579834,
      "learning_rate": 3.884715042028882e-05,
      "logits/chosen": -2.00282621383667,
      "logits/rejected": -1.8116676807403564,
      "logps/chosen": -261.68731689453125,
      "logps/rejected": -236.88723754882812,
      "loss": 0.4541,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": 0.37331563234329224,
      "rewards/margins": 0.7269996404647827,
      "rewards/rejected": -0.35368406772613525,
      "step": 660
    },
    {
      "epoch": 1.182608695652174,
      "grad_norm": 8.491493225097656,
      "learning_rate": 3.799335840750077e-05,
      "logits/chosen": -1.847707748413086,
      "logits/rejected": -1.7938140630722046,
      "logps/chosen": -232.4375457763672,
      "logps/rejected": -193.88209533691406,
      "loss": 0.4513,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": 0.34228259325027466,
      "rewards/margins": 0.7235077619552612,
      "rewards/rejected": -0.3812251687049866,
      "step": 680
    },
    {
      "epoch": 1.2173913043478262,
      "grad_norm": 9.068314552307129,
      "learning_rate": 3.7118273318762275e-05,
      "logits/chosen": -1.8355811834335327,
      "logits/rejected": -1.759516954421997,
      "logps/chosen": -233.2594451904297,
      "logps/rejected": -210.9713134765625,
      "loss": 0.4833,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": 0.14194242656230927,
      "rewards/margins": 0.6029998064041138,
      "rewards/rejected": -0.4610573351383209,
      "step": 700
    },
    {
      "epoch": 1.2521739130434781,
      "grad_norm": 17.053407669067383,
      "learning_rate": 3.622332921389631e-05,
      "logits/chosen": -1.7518088817596436,
      "logits/rejected": -1.478920340538025,
      "logps/chosen": -282.995849609375,
      "logps/rejected": -275.05419921875,
      "loss": 0.4849,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": 0.06487199664115906,
      "rewards/margins": 0.7971529364585876,
      "rewards/rejected": -0.7322808504104614,
      "step": 720
    },
    {
      "epoch": 1.2869565217391306,
      "grad_norm": 6.4601874351501465,
      "learning_rate": 3.530999269700927e-05,
      "logits/chosen": -1.8872184753417969,
      "logits/rejected": -1.879943609237671,
      "logps/chosen": -213.227294921875,
      "logps/rejected": -220.6119384765625,
      "loss": 0.4801,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": 0.2241191565990448,
      "rewards/margins": 0.6762115359306335,
      "rewards/rejected": -0.45209234952926636,
      "step": 740
    },
    {
      "epoch": 1.3217391304347825,
      "grad_norm": 8.053150177001953,
      "learning_rate": 3.43797605130698e-05,
      "logits/chosen": -1.838952660560608,
      "logits/rejected": -1.7539126873016357,
      "logps/chosen": -257.44488525390625,
      "logps/rejected": -249.724853515625,
      "loss": 0.3964,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": 0.1886264681816101,
      "rewards/margins": 0.944858193397522,
      "rewards/rejected": -0.7562317252159119,
      "step": 760
    },
    {
      "epoch": 1.3565217391304347,
      "grad_norm": 7.913947105407715,
      "learning_rate": 3.343415709509384e-05,
      "logits/chosen": -1.9710767269134521,
      "logits/rejected": -1.8989660739898682,
      "logps/chosen": -225.2158966064453,
      "logps/rejected": -223.0483856201172,
      "loss": 0.4586,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -0.010498031973838806,
      "rewards/margins": 0.6508222818374634,
      "rewards/rejected": -0.6613202691078186,
      "step": 780
    },
    {
      "epoch": 1.391304347826087,
      "grad_norm": 11.250261306762695,
      "learning_rate": 3.247473206595536e-05,
      "logits/chosen": -1.84328293800354,
      "logits/rejected": -1.6760717630386353,
      "logps/chosen": -225.2803955078125,
      "logps/rejected": -244.2066650390625,
      "loss": 0.3727,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": 0.10869945585727692,
      "rewards/margins": 1.0443888902664185,
      "rewards/rejected": -0.9356893301010132,
      "step": 800
    },
    {
      "epoch": 1.4260869565217391,
      "grad_norm": 6.7832818031311035,
      "learning_rate": 3.150305769891686e-05,
      "logits/chosen": -2.0656018257141113,
      "logits/rejected": -1.9489715099334717,
      "logps/chosen": -260.4422302246094,
      "logps/rejected": -254.1151580810547,
      "loss": 0.3418,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": 0.12474403530359268,
      "rewards/margins": 1.147352695465088,
      "rewards/rejected": -1.0226085186004639,
      "step": 820
    },
    {
      "epoch": 1.4608695652173913,
      "grad_norm": 7.034339904785156,
      "learning_rate": 3.052072634104116e-05,
      "logits/chosen": -1.9901832342147827,
      "logits/rejected": -1.7710492610931396,
      "logps/chosen": -241.52767944335938,
      "logps/rejected": -227.66543579101562,
      "loss": 0.453,
      "rewards/accuracies": 0.8500000238418579,
      "rewards/chosen": -0.1323578804731369,
      "rewards/margins": 0.8058381080627441,
      "rewards/rejected": -0.9381960034370422,
      "step": 840
    },
    {
      "epoch": 1.4956521739130435,
      "grad_norm": 10.639288902282715,
      "learning_rate": 2.952934780370694e-05,
      "logits/chosen": -1.9354305267333984,
      "logits/rejected": -1.7998301982879639,
      "logps/chosen": -220.52316284179688,
      "logps/rejected": -252.51785278320312,
      "loss": 0.4422,
      "rewards/accuracies": 0.7875000238418579,
      "rewards/chosen": -0.19749096035957336,
      "rewards/margins": 0.921350359916687,
      "rewards/rejected": -1.1188414096832275,
      "step": 860
    },
    {
      "epoch": 1.5304347826086957,
      "grad_norm": 7.125797271728516,
      "learning_rate": 2.853054672450437e-05,
      "logits/chosen": -1.997959852218628,
      "logits/rejected": -1.8970527648925781,
      "logps/chosen": -225.2887725830078,
      "logps/rejected": -211.57553100585938,
      "loss": 0.4266,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -0.11578986793756485,
      "rewards/margins": 0.8534342646598816,
      "rewards/rejected": -0.9692241549491882,
      "step": 880
    },
    {
      "epoch": 1.5652173913043477,
      "grad_norm": 10.725020408630371,
      "learning_rate": 2.7525959904833952e-05,
      "logits/chosen": -1.9115705490112305,
      "logits/rejected": -1.7331674098968506,
      "logps/chosen": -250.17337036132812,
      "logps/rejected": -217.6794891357422,
      "loss": 0.4271,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -0.07513179630041122,
      "rewards/margins": 0.9115946888923645,
      "rewards/rejected": -0.9867265820503235,
      "step": 900
    },
    {
      "epoch": 1.6,
      "grad_norm": 8.170504570007324,
      "learning_rate": 2.6517233627571858e-05,
      "logits/chosen": -1.7568317651748657,
      "logits/rejected": -1.6674795150756836,
      "logps/chosen": -227.0583953857422,
      "logps/rejected": -228.78427124023438,
      "loss": 0.4824,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -0.23290133476257324,
      "rewards/margins": 0.7304381132125854,
      "rewards/rejected": -0.9633393287658691,
      "step": 920
    },
    {
      "epoch": 1.634782608695652,
      "grad_norm": 12.180947303771973,
      "learning_rate": 2.550602095919722e-05,
      "logits/chosen": -1.8955278396606445,
      "logits/rejected": -1.6549444198608398,
      "logps/chosen": -249.22341918945312,
      "logps/rejected": -227.652099609375,
      "loss": 0.4351,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -0.22179707884788513,
      "rewards/margins": 0.8990352749824524,
      "rewards/rejected": -1.1208322048187256,
      "step": 940
    },
    {
      "epoch": 1.6695652173913045,
      "grad_norm": 27.884037017822266,
      "learning_rate": 2.4493979040802785e-05,
      "logits/chosen": -2.0831141471862793,
      "logits/rejected": -1.9302669763565063,
      "logps/chosen": -252.7986602783203,
      "logps/rejected": -237.84866333007812,
      "loss": 0.4438,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -0.2755606770515442,
      "rewards/margins": 0.91966313123703,
      "rewards/rejected": -1.1952238082885742,
      "step": 960
    },
    {
      "epoch": 1.7043478260869565,
      "grad_norm": 16.341970443725586,
      "learning_rate": 2.348276637242814e-05,
      "logits/chosen": -2.189927816390991,
      "logits/rejected": -2.0129952430725098,
      "logps/chosen": -215.6380157470703,
      "logps/rejected": -227.424072265625,
      "loss": 0.4052,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -0.11559321731328964,
      "rewards/margins": 1.045290470123291,
      "rewards/rejected": -1.1608837842941284,
      "step": 980
    },
    {
      "epoch": 1.7391304347826086,
      "grad_norm": 14.88922119140625,
      "learning_rate": 2.247404009516605e-05,
      "logits/chosen": -1.910424828529358,
      "logits/rejected": -1.7708288431167603,
      "logps/chosen": -265.3670349121094,
      "logps/rejected": -264.0600891113281,
      "loss": 0.4238,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -0.29969021677970886,
      "rewards/margins": 1.4536973237991333,
      "rewards/rejected": -1.753387689590454,
      "step": 1000
    },
    {
      "epoch": 1.7739130434782608,
      "grad_norm": 9.915694236755371,
      "learning_rate": 2.1469453275495636e-05,
      "logits/chosen": -2.1804115772247314,
      "logits/rejected": -2.0243029594421387,
      "logps/chosen": -245.24154663085938,
      "logps/rejected": -247.73574829101562,
      "loss": 0.4219,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -0.3547806143760681,
      "rewards/margins": 0.8745423555374146,
      "rewards/rejected": -1.229322910308838,
      "step": 1020
    },
    {
      "epoch": 1.808695652173913,
      "grad_norm": 12.441720962524414,
      "learning_rate": 2.047065219629306e-05,
      "logits/chosen": -1.9822866916656494,
      "logits/rejected": -1.7692426443099976,
      "logps/chosen": -228.59805297851562,
      "logps/rejected": -231.79153442382812,
      "loss": 0.4331,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -0.3878992199897766,
      "rewards/margins": 0.9061216115951538,
      "rewards/rejected": -1.2940208911895752,
      "step": 1040
    },
    {
      "epoch": 1.8434782608695652,
      "grad_norm": 17.83819580078125,
      "learning_rate": 1.947927365895885e-05,
      "logits/chosen": -2.0939254760742188,
      "logits/rejected": -1.9535388946533203,
      "logps/chosen": -236.0308837890625,
      "logps/rejected": -246.40097045898438,
      "loss": 0.4664,
      "rewards/accuracies": 0.800000011920929,
      "rewards/chosen": -0.4841884672641754,
      "rewards/margins": 0.9934444427490234,
      "rewards/rejected": -1.4776328802108765,
      "step": 1060
    },
    {
      "epoch": 1.8782608695652174,
      "grad_norm": 8.311237335205078,
      "learning_rate": 1.8496942301083144e-05,
      "logits/chosen": -1.920526146888733,
      "logits/rejected": -1.7378467321395874,
      "logps/chosen": -221.06484985351562,
      "logps/rejected": -250.1088104248047,
      "loss": 0.4334,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": -0.406815767288208,
      "rewards/margins": 0.9545083045959473,
      "rewards/rejected": -1.3613240718841553,
      "step": 1080
    },
    {
      "epoch": 1.9130434782608696,
      "grad_norm": 10.05217456817627,
      "learning_rate": 1.7525267934044643e-05,
      "logits/chosen": -2.0177161693573,
      "logits/rejected": -1.9588260650634766,
      "logps/chosen": -215.3892822265625,
      "logps/rejected": -192.3944854736328,
      "loss": 0.419,
      "rewards/accuracies": 0.862500011920929,
      "rewards/chosen": -0.3460957407951355,
      "rewards/margins": 0.8491647839546204,
      "rewards/rejected": -1.1952605247497559,
      "step": 1100
    },
    {
      "epoch": 1.9478260869565216,
      "grad_norm": 19.32228660583496,
      "learning_rate": 1.6565842904906153e-05,
      "logits/chosen": -2.1094768047332764,
      "logits/rejected": -1.9160248041152954,
      "logps/chosen": -261.18414306640625,
      "logps/rejected": -258.140380859375,
      "loss": 0.369,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -0.11633467674255371,
      "rewards/margins": 1.203804850578308,
      "rewards/rejected": -1.3201395273208618,
      "step": 1120
    },
    {
      "epoch": 1.982608695652174,
      "grad_norm": 9.018716812133789,
      "learning_rate": 1.5620239486930198e-05,
      "logits/chosen": -2.089017391204834,
      "logits/rejected": -1.9475901126861572,
      "logps/chosen": -216.5394744873047,
      "logps/rejected": -253.48568725585938,
      "loss": 0.3985,
      "rewards/accuracies": 0.824999988079071,
      "rewards/chosen": -0.1108493059873581,
      "rewards/margins": 1.0907618999481201,
      "rewards/rejected": -1.2016112804412842,
      "step": 1140
    },
    {
      "epoch": 2.017391304347826,
      "grad_norm": 6.4488348960876465,
      "learning_rate": 1.4690007302990738e-05,
      "logits/chosen": -1.8462404012680054,
      "logits/rejected": -1.734833002090454,
      "logps/chosen": -246.96475219726562,
      "logps/rejected": -267.7756652832031,
      "loss": 0.3176,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.034029800444841385,
      "rewards/margins": 1.316335916519165,
      "rewards/rejected": -1.3503655195236206,
      "step": 1160
    },
    {
      "epoch": 2.0521739130434784,
      "grad_norm": 10.240797996520996,
      "learning_rate": 1.3776670786103685e-05,
      "logits/chosen": -2.048490047454834,
      "logits/rejected": -1.9898416996002197,
      "logps/chosen": -213.22360229492188,
      "logps/rejected": -239.8614959716797,
      "loss": 0.2592,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -0.004558551125228405,
      "rewards/margins": 1.6462080478668213,
      "rewards/rejected": -1.6507667303085327,
      "step": 1180
    },
    {
      "epoch": 2.0869565217391304,
      "grad_norm": 14.624405860900879,
      "learning_rate": 1.2881726681237727e-05,
      "logits/chosen": -2.0798559188842773,
      "logits/rejected": -1.9516254663467407,
      "logps/chosen": -260.21685791015625,
      "logps/rejected": -267.9263610839844,
      "loss": 0.2733,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -0.1856091320514679,
      "rewards/margins": 1.5184705257415771,
      "rewards/rejected": -1.7040798664093018,
      "step": 1200
    },
    {
      "epoch": 2.121739130434783,
      "grad_norm": 6.668664455413818,
      "learning_rate": 1.2006641592499232e-05,
      "logits/chosen": -2.2524824142456055,
      "logits/rejected": -2.124587059020996,
      "logps/chosen": -238.7543182373047,
      "logps/rejected": -243.95962524414062,
      "loss": 0.2994,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -0.17977575957775116,
      "rewards/margins": 1.4066886901855469,
      "rewards/rejected": -1.586464524269104,
      "step": 1220
    },
    {
      "epoch": 2.1565217391304348,
      "grad_norm": 8.012466430664062,
      "learning_rate": 1.1152849579711186e-05,
      "logits/chosen": -2.0989341735839844,
      "logits/rejected": -1.8572406768798828,
      "logps/chosen": -271.4320068359375,
      "logps/rejected": -295.912109375,
      "loss": 0.2492,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.28962770104408264,
      "rewards/margins": 1.7525790929794312,
      "rewards/rejected": -2.0422065258026123,
      "step": 1240
    },
    {
      "epoch": 2.1913043478260867,
      "grad_norm": 6.356428623199463,
      "learning_rate": 1.0321749808324425e-05,
      "logits/chosen": -2.432508945465088,
      "logits/rejected": -2.215968608856201,
      "logps/chosen": -198.7462158203125,
      "logps/rejected": -231.35128784179688,
      "loss": 0.2431,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -0.2968668043613434,
      "rewards/margins": 1.8506596088409424,
      "rewards/rejected": -2.147526502609253,
      "step": 1260
    },
    {
      "epoch": 2.226086956521739,
      "grad_norm": 6.682183265686035,
      "learning_rate": 9.514704256512669e-06,
      "logits/chosen": -2.1501526832580566,
      "logits/rejected": -2.024315357208252,
      "logps/chosen": -233.0206298828125,
      "logps/rejected": -264.80352783203125,
      "loss": 0.2604,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -0.46145397424697876,
      "rewards/margins": 1.7945388555526733,
      "rewards/rejected": -2.255992889404297,
      "step": 1280
    },
    {
      "epoch": 2.260869565217391,
      "grad_norm": 13.587080955505371,
      "learning_rate": 8.73303548320884e-06,
      "logits/chosen": -2.3537378311157227,
      "logits/rejected": -2.093008041381836,
      "logps/chosen": -245.22885131835938,
      "logps/rejected": -265.4472351074219,
      "loss": 0.297,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -0.5968121886253357,
      "rewards/margins": 1.6744874715805054,
      "rewards/rejected": -2.2712998390197754,
      "step": 1300
    },
    {
      "epoch": 2.2956521739130435,
      "grad_norm": 16.16388702392578,
      "learning_rate": 7.97802446074017e-06,
      "logits/chosen": -2.2583096027374268,
      "logits/rejected": -2.194161891937256,
      "logps/chosen": -244.65505981445312,
      "logps/rejected": -227.6724090576172,
      "loss": 0.2906,
      "rewards/accuracies": 0.925000011920929,
      "rewards/chosen": -0.3115359842777252,
      "rewards/margins": 1.6379696130752563,
      "rewards/rejected": -1.9495055675506592,
      "step": 1320
    },
    {
      "epoch": 2.3304347826086955,
      "grad_norm": 8.984466552734375,
      "learning_rate": 7.250908475614185e-06,
      "logits/chosen": -2.3528871536254883,
      "logits/rejected": -2.1001458168029785,
      "logps/chosen": -240.34341430664062,
      "logps/rejected": -253.21603393554688,
      "loss": 0.277,
      "rewards/accuracies": 0.925000011920929,
      "rewards/chosen": -0.42852073907852173,
      "rewards/margins": 1.671264886856079,
      "rewards/rejected": -2.099785566329956,
      "step": 1340
    },
    {
      "epoch": 2.365217391304348,
      "grad_norm": 13.066025733947754,
      "learning_rate": 6.5528791008953955e-06,
      "logits/chosen": -2.278102397918701,
      "logits/rejected": -2.134380340576172,
      "logps/chosen": -238.88217163085938,
      "logps/rejected": -245.92379760742188,
      "loss": 0.2817,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -0.666481614112854,
      "rewards/margins": 1.6902564764022827,
      "rewards/rejected": -2.3567380905151367,
      "step": 1360
    },
    {
      "epoch": 2.4,
      "grad_norm": 17.24361228942871,
      "learning_rate": 5.8850802434957305e-06,
      "logits/chosen": -2.536162853240967,
      "logits/rejected": -2.4459969997406006,
      "logps/chosen": -224.559814453125,
      "logps/rejected": -238.0598602294922,
      "loss": 0.2354,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -0.38834133744239807,
      "rewards/margins": 1.765059471130371,
      "rewards/rejected": -2.1534006595611572,
      "step": 1380
    },
    {
      "epoch": 2.4347826086956523,
      "grad_norm": 9.911070823669434,
      "learning_rate": 5.24860626957861e-06,
      "logits/chosen": -2.5572147369384766,
      "logits/rejected": -2.341346263885498,
      "logps/chosen": -219.4927520751953,
      "logps/rejected": -231.81454467773438,
      "loss": 0.2596,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -0.4178052544593811,
      "rewards/margins": 1.6376756429672241,
      "rewards/rejected": -2.05548095703125,
      "step": 1400
    },
    {
      "epoch": 2.4695652173913043,
      "grad_norm": 10.185816764831543,
      "learning_rate": 4.644500211148687e-06,
      "logits/chosen": -2.4864494800567627,
      "logits/rejected": -2.2847371101379395,
      "logps/chosen": -230.17941284179688,
      "logps/rejected": -237.2469482421875,
      "loss": 0.2732,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.4635985791683197,
      "rewards/margins": 1.705138921737671,
      "rewards/rejected": -2.1687376499176025,
      "step": 1420
    },
    {
      "epoch": 2.5043478260869563,
      "grad_norm": 12.778227806091309,
      "learning_rate": 4.073752056766342e-06,
      "logits/chosen": -2.6473135948181152,
      "logits/rejected": -2.4954311847686768,
      "logps/chosen": -244.65298461914062,
      "logps/rejected": -269.6245422363281,
      "loss": 0.2654,
      "rewards/accuracies": 0.925000011920929,
      "rewards/chosen": -0.6651582717895508,
      "rewards/margins": 2.507225513458252,
      "rewards/rejected": -3.1723837852478027,
      "step": 1440
    },
    {
      "epoch": 2.5391304347826087,
      "grad_norm": 6.714966773986816,
      "learning_rate": 3.537297129187925e-06,
      "logits/chosen": -2.445451498031616,
      "logits/rejected": -2.3164865970611572,
      "logps/chosen": -248.0607452392578,
      "logps/rejected": -217.83499145507812,
      "loss": 0.3082,
      "rewards/accuracies": 0.8999999761581421,
      "rewards/chosen": -0.6917190551757812,
      "rewards/margins": 1.652078628540039,
      "rewards/rejected": -2.3437976837158203,
      "step": 1460
    },
    {
      "epoch": 2.573913043478261,
      "grad_norm": 6.1918768882751465,
      "learning_rate": 3.036014552590455e-06,
      "logits/chosen": -2.3383378982543945,
      "logits/rejected": -2.328526258468628,
      "logps/chosen": -256.5252685546875,
      "logps/rejected": -258.12139892578125,
      "loss": 0.2116,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -0.40698009729385376,
      "rewards/margins": 2.0357155799865723,
      "rewards/rejected": -2.4426956176757812,
      "step": 1480
    },
    {
      "epoch": 2.608695652173913,
      "grad_norm": 9.144776344299316,
      "learning_rate": 2.570725811892727e-06,
      "logits/chosen": -2.4126973152160645,
      "logits/rejected": -2.3836772441864014,
      "logps/chosen": -264.09747314453125,
      "logps/rejected": -238.5009765625,
      "loss": 0.3582,
      "rewards/accuracies": 0.887499988079071,
      "rewards/chosen": -0.5808871388435364,
      "rewards/margins": 1.4540178775787354,
      "rewards/rejected": -2.034905195236206,
      "step": 1500
    },
    {
      "epoch": 2.643478260869565,
      "grad_norm": 17.08951759338379,
      "learning_rate": 2.142193406533591e-06,
      "logits/chosen": -2.3740134239196777,
      "logits/rejected": -2.2148690223693848,
      "logps/chosen": -266.10638427734375,
      "logps/rejected": -256.29754638671875,
      "loss": 0.2307,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -0.6560419797897339,
      "rewards/margins": 1.8383108377456665,
      "rewards/rejected": -2.4943528175354004,
      "step": 1520
    },
    {
      "epoch": 2.6782608695652175,
      "grad_norm": 13.185047149658203,
      "learning_rate": 1.7511196009137088e-06,
      "logits/chosen": -2.3852131366729736,
      "logits/rejected": -2.3204197883605957,
      "logps/chosen": -214.6347198486328,
      "logps/rejected": -233.49032592773438,
      "loss": 0.2306,
      "rewards/accuracies": 0.987500011920929,
      "rewards/chosen": -0.44119733572006226,
      "rewards/margins": 1.8887393474578857,
      "rewards/rejected": -2.3299365043640137,
      "step": 1540
    },
    {
      "epoch": 2.7130434782608694,
      "grad_norm": 8.74937915802002,
      "learning_rate": 1.3981452735483958e-06,
      "logits/chosen": -2.36160945892334,
      "logits/rejected": -2.2787411212921143,
      "logps/chosen": -237.0846710205078,
      "logps/rejected": -248.3704833984375,
      "loss": 0.2647,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -0.6648741364479065,
      "rewards/margins": 1.6980648040771484,
      "rewards/rejected": -2.36293888092041,
      "step": 1560
    },
    {
      "epoch": 2.747826086956522,
      "grad_norm": 3.4870636463165283,
      "learning_rate": 1.0838488668176383e-06,
      "logits/chosen": -2.3855602741241455,
      "logits/rejected": -2.311100721359253,
      "logps/chosen": -233.8466033935547,
      "logps/rejected": -233.7255096435547,
      "loss": 0.2317,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -0.4935809075832367,
      "rewards/margins": 1.8637367486953735,
      "rewards/rejected": -2.3573176860809326,
      "step": 1580
    },
    {
      "epoch": 2.782608695652174,
      "grad_norm": 8.757014274597168,
      "learning_rate": 8.087454390342725e-07,
      "logits/chosen": -2.403104066848755,
      "logits/rejected": -2.310175657272339,
      "logps/chosen": -238.98690795898438,
      "logps/rejected": -257.5694885253906,
      "loss": 0.193,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -0.2654953598976135,
      "rewards/margins": 2.1225082874298096,
      "rewards/rejected": -2.3880038261413574,
      "step": 1600
    },
    {
      "epoch": 2.8173913043478263,
      "grad_norm": 7.590307712554932,
      "learning_rate": 5.732858203838648e-07,
      "logits/chosen": -2.3047714233398438,
      "logits/rejected": -2.172574281692505,
      "logps/chosen": -251.88021850585938,
      "logps/rejected": -249.40121459960938,
      "loss": 0.2367,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -0.39443057775497437,
      "rewards/margins": 1.6924259662628174,
      "rewards/rejected": -2.0868566036224365,
      "step": 1620
    },
    {
      "epoch": 2.8521739130434782,
      "grad_norm": 7.317084312438965,
      "learning_rate": 3.778558741194677e-07,
      "logits/chosen": -2.614445924758911,
      "logits/rejected": -2.584519863128662,
      "logps/chosen": -231.53561401367188,
      "logps/rejected": -239.0364227294922,
      "loss": 0.2468,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.5035575032234192,
      "rewards/margins": 1.8295679092407227,
      "rewards/rejected": -2.333125352859497,
      "step": 1640
    },
    {
      "epoch": 2.8869565217391306,
      "grad_norm": 11.280546188354492,
      "learning_rate": 2.2277586422198017e-07,
      "logits/chosen": -2.3740477561950684,
      "logits/rejected": -2.3213353157043457,
      "logps/chosen": -270.4082946777344,
      "logps/rejected": -274.63006591796875,
      "loss": 0.2183,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -0.5822601318359375,
      "rewards/margins": 2.021491527557373,
      "rewards/rejected": -2.6037518978118896,
      "step": 1660
    },
    {
      "epoch": 2.9217391304347826,
      "grad_norm": 5.151345252990723,
      "learning_rate": 1.0829993056236943e-07,
      "logits/chosen": -2.52005672454834,
      "logits/rejected": -2.2481565475463867,
      "logps/chosen": -221.18460083007812,
      "logps/rejected": -222.265625,
      "loss": 0.2906,
      "rewards/accuracies": 0.925000011920929,
      "rewards/chosen": -0.5663747191429138,
      "rewards/margins": 1.7730001211166382,
      "rewards/rejected": -2.3393750190734863,
      "step": 1680
    },
    {
      "epoch": 2.9565217391304346,
      "grad_norm": 5.741997241973877,
      "learning_rate": 3.4615672425861165e-08,
      "logits/chosen": -2.5147652626037598,
      "logits/rejected": -2.3355953693389893,
      "logps/chosen": -230.339599609375,
      "logps/rejected": -230.0087890625,
      "loss": 0.297,
      "rewards/accuracies": 0.9125000238418579,
      "rewards/chosen": -0.6586796045303345,
      "rewards/margins": 1.4838371276855469,
      "rewards/rejected": -2.142516613006592,
      "step": 1700
    },
    {
      "epoch": 2.991304347826087,
      "grad_norm": 10.470154762268066,
      "learning_rate": 1.8438410805732277e-09,
      "logits/chosen": -2.4777517318725586,
      "logits/rejected": -2.344724416732788,
      "logps/chosen": -270.841064453125,
      "logps/rejected": -238.16018676757812,
      "loss": 0.2506,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -0.5623409152030945,
      "rewards/margins": 1.6283094882965088,
      "rewards/rejected": -2.190650463104248,
      "step": 1720
    }
  ],
  "logging_steps": 20,
  "max_steps": 1725,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 0.0,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
